name: EKS Deployment and Cleanup

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform: deploy or destroy'
        required: true
        default: 'deploy'
        type: choice
        options:
          - deploy
          - destroy
      cluster_name:
        description: 'EKS cluster name'
        required: true
        default: 'flask-auto-cluster'
        type: string

jobs:
  deploy:
    if: ${{ github.event.inputs.action == 'deploy' }}
    runs-on: ubuntu-latest
    environment: ENV
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ vars.AWS_ACCOUNT }}:role/GitHubActionsRole
          aws-region: ap-southeast-2

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Create flask-app ECR repository if not exists
        run: |
          aws ecr describe-repositories --repository-names flask-app --region ap-southeast-2 || \
          aws ecr create-repository --repository-name flask-app --region ap-southeast-2

      - name: Build, tag, and push flask-app image
        run: |
          cd flask-app
          docker build -t flask-app .
          docker tag flask-app:latest ${{ vars.AWS_ACCOUNT }}.dkr.ecr.ap-southeast-2.amazonaws.com/flask-app:latest
          docker push ${{ vars.AWS_ACCOUNT }}.dkr.ecr.ap-southeast-2.amazonaws.com/flask-app:latest

      - name: Install eksctl and kubectl
        run: |
          curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          sudo apt-get update && sudo apt-get install -y gettext-base

      - name: Create EKS cluster with eksctl
        env:
          CLUSTER_NAME: ${{ github.event.inputs.cluster_name }}
        run: |
          envsubst < eksctl/cluster.yaml > eksctl/cluster_updated.yaml
          mv eksctl/cluster_updated.yaml eksctl/cluster.yaml

          CLUSTER_REGION="ap-southeast-2"
          if ! eksctl get cluster --name ${CLUSTER_NAME} --region ${CLUSTER_REGION} --output json | jq -e '.[] | select(.Status=="ACTIVE")'; then
            eksctl create cluster -f eksctl/cluster.yaml
          else
            echo "Cluster ${CLUSTER_NAME} already exists in region ${CLUSTER_REGION} and is ACTIVE."
          fi

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --name ${{ github.event.inputs.cluster_name }} --region ap-southeast-2

      - name: Install Helm
        run: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
          chmod 700 get_helm.sh
          ./get_helm.sh

      - name: Install AWS Load Balancer Controller
        run: |
          helm repo add eks https://aws.github.io/eks-charts
          helm repo update
          helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
            -n kube-system \
            --set clusterName=${{ github.event.inputs.cluster_name }} \
            --set serviceAccount.create=false \
            --set serviceAccount.name=aws-load-balancer-controller \
            --set region=ap-southeast-2 \
            --set vpcId=$(aws eks describe-cluster --name ${{ github.event.inputs.cluster_name }} --query "cluster.resourcesVpcConfig.vpcId" --output text) \
            --set env.AWS_REGION=ap-southeast-2

      - name: Wait for AWS Load Balancer Controller to be ready
        run: |
          echo "Waiting for AWS Load Balancer Controller to be ready..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=aws-load-balancer-controller -n kube-system --timeout=300s
          echo "Waiting for webhook service endpoints..."
          for i in {1..30}; do
            ENDPOINTS=$(kubectl get endpoints aws-load-balancer-webhook-service -n kube-system -o jsonpath='{.subsets[*].addresses[*].ip}' 2>/dev/null || echo "")
            if [ ! -z "$ENDPOINTS" ]; then
              echo "AWS Load Balancer Controller webhook service is ready with endpoints: $ENDPOINTS"
              break
            fi
            echo "Waiting for webhook endpoints... ($i/30)"
            sleep 10
          done
          echo "Verifying webhook service readiness..."
          kubectl get svc aws-load-balancer-webhook-service -n kube-system
          kubectl get endpoints aws-load-balancer-webhook-service -n kube-system

      - name: Create Kubernetes namespace
        run: |
          kubectl create namespace app --dry-run=client -o yaml | kubectl apply -f -

      - name: Create Kubernetes secrets for ECR
        run: |
          kubectl create secret docker-registry ecr-auth \
            --docker-server=${{ vars.AWS_ACCOUNT }}.dkr.ecr.ap-southeast-2.amazonaws.com \
            --docker-username=AWS \
            --docker-password=$(aws ecr get-login-password --region ap-southeast-2) \
            --namespace app \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Deploy Flask application
        run: |
          echo "Replacing AWS account ID in deployment file..."
          sed -i "s|<AWS_ACCOUNT_ID>|${{ vars.AWS_ACCOUNT }}|g" k8s/flask.yaml
          echo "Applying Kubernetes manifests..."
          kubectl apply -f k8s/flask.yaml

      - name: Wait for deployment to be ready
        run: |
          echo "Waiting for flask-app deployment..."
          kubectl rollout status deployment/flask-app -n app --timeout=600s

      - name: Wait for ALB to be provisioned
        run: |
          echo "Waiting for ALB to be provisioned..."
          for i in {1..30}; do
            ALB_URL=$(kubectl get ingress flask-ingress -n app -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null)
            if [ ! -z "$ALB_URL" ]; then
              echo "ALB URL: http://$ALB_URL"
              echo "Flask API URL: http://$ALB_URL/api/hello"
              echo "::set-output name=alb_url::$ALB_URL"
              break
            fi
            echo "Waiting for ALB... ($i/30)"
            sleep 10
          done

  destroy:
    if: ${{ github.event.inputs.action == 'destroy' }}
    runs-on: ubuntu-latest
    environment: ENV
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ vars.AWS_ACCOUNT }}:role/GitHubActionsRole
          aws-region: ap-southeast-2

      - name: Install eksctl and kubectl
        run: |
          curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --name ${{ github.event.inputs.cluster_name }} --region ap-southeast-2

      - name: Force delete unevictable pods
        run: |
          echo "Checking for unevictable pods..."
          kubectl delete pods --all -n app --force --grace-period=0 || true
          kubectl get pods --all-namespaces --field-selector metadata.namespace!=kube-system -o json | \
          jq -r '.items[] | select(.status.phase != "Succeeded") | "\(.metadata.name) -n \(.metadata.namespace)"' | \
          xargs -r -n 3 kubectl delete pod --force --grace-period=0 || true

      - name: Delete EKS cluster with force
        env:
          CLUSTER_NAME: ${{ github.event.inputs.cluster_name }}
        run: |
          envsubst < eksctl/cluster.yaml > eksctl/cluster_updated.yaml
          mv eksctl/cluster_updated.yaml eksctl/cluster.yaml
          eksctl delete cluster -f eksctl/cluster.yaml --force --disable-nodegroup-eviction

      - name: Delete flask-app ECR repository
        run: |
          aws ecr delete-repository --repository-name flask-app --region ap-southeast-2 --force || true 